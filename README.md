# Machine Learning Blog Posts

Links to blog posts about different topics in ML and AI.

Contributions are welcome, just submit a pull request:
* Blog posts only, no papers!
* Follow the formatting conventions
* Pull request and commit titles are useful
* Try not to submit duplicates
* Improvements to organization are welcome =D


-----

### Attention

[Attention and Augmented Recurrent Neural Networks](https://distill.pub/2016/augmented-rnns/)\
Chris Olah, Shan Carter, Sep 2016

[Attention in Neural Networks and How to Use It](http://akosiorek.github.io/ml/2017/10/14/visual-attention.html)\
Adam Kosiorek, Oct 2017

### Convolutional neural networks (CNNs)

[Conv Nets: A Modular Perspective](http://colah.github.io/posts/2014-07-Conv-Nets-Modular/)\
Chris Olah, Jul 2014

[Understanding Convolutions](http://colah.github.io/posts/2014-07-Understanding-Convolutions/)\
Chris Olah, Jul 2014

### Dimensionality reduction

[Visualizing MNIST: An Exploration of Dimensionality Reduction](http://colah.github.io/posts/2014-10-Visualizing-MNIST/)\
Chris Olah, Oct 2014

### Generative adversarial networks (GANs)

[InfoGAN: using the variational bound on mutual information (twice)](https://www.inference.vc/infogan-variational-bound-on-mutual-information-twice/)\
Ferenc Huszar, Aug 2016

[Open Questions about Generative Adversarial Networks](https://distill.pub/2019/gan-open-problems/)\
Augustus Odena, Apr 2019

### Gaussian processes

[A Visual Exploration of Gaussian Processes](https://distill.pub/2019/visual-exploration-gaussian-processes/)\
Jochen Gortler, Rebecca Kehlbeck, Oliver Deussen, Apr 2019

### Information theory

[Visual Information Theory](http://colah.github.io/posts/2015-09-Visual-Information/)\
Chris Olah, Oct 2015


### Normalizing flows

[Normalizing Flows Tutorial, Part 1: Distributions and Determinants](https://blog.evjang.com/2018/01/nf1.html)\
Eric Jang, Jan 2018

[Normalizing Flows Tutorial, Part 2: Modern Normalizing Flows](https://blog.evjang.com/2018/01/nf2.html)\
Eric Jang, Jan 2018

[Normalizing Flows](http://akosiorek.github.io/ml/2018/04/03/norm_flows.html)\
Adam Kosiorek, Apr 2018

[Change of Variables: A precursor to normalizing flow](http://ruishu.io/2018/05/19/change-of-variables/)\
Rui Shu, May 2018

[Flow-based Deep Generative Models](https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html)\
Lilian Weng, Oct 2018

### Optimization

[Why Momentum Really Works](https://distill.pub/2017/momentum/)\
Gabriel Goh, Apr 2017

### Probability

[Gaussian Distributions are Soap Bubbles](https://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/)\
Ference Huszar, Nov 2017

### Reinforcement learning (RL)

[Deep Reinforcement Learning: Pong from Pixels](http://karpathy.github.io/2016/05/31/rl/)\
Andrej Karpathy, May 2016

### Recurrent neural networks (RNNs/LSTMs)

[The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\
Andrej Karpathy, May 2015

[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\
Chris Olah, Aug 2015

[Visualizing memorization in RNNs](https://distill.pub/2019/memorization-in-rnns/)\
Andreas Madsen, Mar 2019

### Training neural networks

[A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe/)\
Andrej Karpathy, Apr 2019

### Variational autoencoders (VAEs)

[A Tutorial on Information Maximizing Variational Autoencoders (InfoVAE)](https://ermongroup.github.io/blog/a-tutorial-on-mmd-variational-autoencoders/)\
Shengjia Zhao, Dec 2017

[Density Estimation: Variational autoencoders](http://ruishu.io/2018/03/14/vae/)\
Rui Shu, Mar 2018

[What is wrong with VAEs?](http://akosiorek.github.io/ml/2018/03/14/what_is_wrong_with_vaes.html)\
Adam Kosiorek, Mar 2018
